def @main(%serving_default_input:0: Tensor[(1, 256, 256, 3), uint8]) -> Tensor[(1, 1, 17, 3), float32] {
  %0 = cast(%serving_default_input:0, dtype="float32") /* ty=Tensor[(1, 256, 256, 3), float32] */;
  %1 = qnn.quantize(%0, 1f /* ty=float32 */, -128 /* ty=int32 */, out_dtype="int8", axis=1) /* ty=Tensor[(1, 256, 256, 3), int8] */;
  %2 = qnn.subtract(%1, meta[relay.Constant][0] /* ty=Tensor[(1, 1, 1, 3), int8] */, 1f /* ty=float32 */, -128 /* ty=int32 */, 1e-06f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, -128 /* ty=int32 */) /* ty=Tensor[(1, 256, 256, 3), int8] */;
  %3 = qnn.mul(%2, meta[relay.Constant][1] /* ty=int8 */, 1f /* ty=float32 */, -128 /* ty=int32 */, 3.07574e-05f /* ty=float32 */, -128 /* ty=int32 */, 0.00784314f /* ty=float32 */, -128 /* ty=int32 */) /* ty=Tensor[(1, 256, 256, 3), int8] */;
  %4 = qnn.subtract(%3, meta[relay.Constant][1] /* ty=int8 */, 0.00784314f /* ty=float32 */, -128 /* ty=int32 */, 0.00392157f /* ty=float32 */, -128 /* ty=int32 */, 0.00784314f /* ty=float32 */, -1 /* ty=int32 */) /* ty=Tensor[(1, 256, 256, 3), int8] */;
  %5 = transpose(%4, axes=[0, 3, 1, 2]) /* ty=Tensor[(1, 3, 256, 256), int8] */;
  %6 = qnn.conv2d(%5, meta[relay.Constant][2] /* ty=Tensor[(56, 3, 3, 3), int8] */, -1 /* ty=int32 */, meta[relay.Constant][3] /* ty=Tensor[(56), int32] */, 0.00784314f /* ty=float32 */, meta[relay.Constant][4] /* ty=Tensor[(56), float32] */, strides=[2, 2], padding=[0, 0, 1, 1], channels=56, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 56, 128, 128), int32] */;
  %7 = nn.bias_add(%6, meta[relay.Constant][5] /* ty=Tensor[(56), int32] */) /* ty=Tensor[(1, 56, 128, 128), int32] */;
  %8 = qnn.quantize(meta[relay.Constant][6] /* ty=Tensor[(1, 56, 1, 1), float32] */, meta[relay.Constant][7] /* ty=Tensor[(56), float32] */, meta[relay.Constant][8] /* ty=Tensor[(56), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 56, 1, 1), int32] */;
  %9 = maximum(%7, %8) /* ty=Tensor[(1, 56, 128, 128), int32] */;
  %10 = qnn.quantize(meta[relay.Constant][9] /* ty=Tensor[(1, 56, 1, 1), float32] */, meta[relay.Constant][7] /* ty=Tensor[(56), float32] */, meta[relay.Constant][8] /* ty=Tensor[(56), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 56, 1, 1), int32] */;
  %11 = minimum(%9, %10) /* ty=Tensor[(1, 56, 128, 128), int32] */;
  %12 = qnn.requantize(%11, meta[relay.Constant][7] /* ty=Tensor[(56), float32] */, meta[relay.Constant][8] /* ty=Tensor[(56), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 56, 128, 128), int8] */;
  %13 = qnn.conv2d(%12, meta[relay.Constant][10] /* ty=Tensor[(56, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][11] /* ty=Tensor[(56), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][12] /* ty=Tensor[(56), float32] */, padding=[1, 1, 1, 1], groups=56, channels=56, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 56, 128, 128), int32] */;
  %14 = nn.bias_add(%13, meta[relay.Constant][13] /* ty=Tensor[(56), int32] */) /* ty=Tensor[(1, 56, 128, 128), int32] */;
  %15 = qnn.quantize(meta[relay.Constant][14] /* ty=Tensor[(1, 56, 1, 1), float32] */, meta[relay.Constant][15] /* ty=Tensor[(56), float32] */, meta[relay.Constant][16] /* ty=Tensor[(56), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 56, 1, 1), int32] */;
  %16 = maximum(%14, %15) /* ty=Tensor[(1, 56, 128, 128), int32] */;
  %17 = qnn.quantize(meta[relay.Constant][17] /* ty=Tensor[(1, 56, 1, 1), float32] */, meta[relay.Constant][15] /* ty=Tensor[(56), float32] */, meta[relay.Constant][16] /* ty=Tensor[(56), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 56, 1, 1), int32] */;
  %18 = minimum(%16, %17) /* ty=Tensor[(1, 56, 128, 128), int32] */;
  %19 = qnn.requantize(%18, meta[relay.Constant][15] /* ty=Tensor[(56), float32] */, meta[relay.Constant][16] /* ty=Tensor[(56), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 56, 128, 128), int8] */;
  %20 = qnn.conv2d(%19, meta[relay.Constant][18] /* ty=Tensor[(32, 56, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][19] /* ty=Tensor[(32), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][20] /* ty=Tensor[(32), float32] */, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 32, 128, 128), int32] */;
  %21 = nn.bias_add(%20, meta[relay.Constant][21] /* ty=Tensor[(32), int32] */) /* ty=Tensor[(1, 32, 128, 128), int32] */;
  %22 = qnn.requantize(%21, meta[relay.Constant][22] /* ty=Tensor[(32), float32] */, meta[relay.Constant][23] /* ty=Tensor[(32), int32] */, 0.327041f /* ty=float32 */, 14 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 32, 128, 128), int8] */;
  %23 = qnn.conv2d(%22, meta[relay.Constant][24] /* ty=Tensor[(192, 32, 1, 1), int8] */, 14 /* ty=int32 */, meta[relay.Constant][25] /* ty=Tensor[(192), int32] */, 0.327041f /* ty=float32 */, meta[relay.Constant][26] /* ty=Tensor[(192), float32] */, padding=[0, 0, 0, 0], channels=192, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 192, 128, 128), int32] */;
  %24 = nn.bias_add(%23, meta[relay.Constant][27] /* ty=Tensor[(192), int32] */) /* ty=Tensor[(1, 192, 128, 128), int32] */;
  %25 = qnn.quantize(meta[relay.Constant][28] /* ty=Tensor[(1, 192, 1, 1), float32] */, meta[relay.Constant][29] /* ty=Tensor[(192), float32] */, meta[relay.Constant][30] /* ty=Tensor[(192), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 192, 1, 1), int32] */;
  %26 = maximum(%24, %25) /* ty=Tensor[(1, 192, 128, 128), int32] */;
  %27 = qnn.quantize(meta[relay.Constant][31] /* ty=Tensor[(1, 192, 1, 1), float32] */, meta[relay.Constant][29] /* ty=Tensor[(192), float32] */, meta[relay.Constant][30] /* ty=Tensor[(192), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 192, 1, 1), int32] */;
  %28 = minimum(%26, %27) /* ty=Tensor[(1, 192, 128, 128), int32] */;
  %29 = qnn.requantize(%28, meta[relay.Constant][29] /* ty=Tensor[(192), float32] */, meta[relay.Constant][30] /* ty=Tensor[(192), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 192, 128, 128), int8] */;
  %30 = qnn.conv2d(%29, meta[relay.Constant][32] /* ty=Tensor[(192, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][33] /* ty=Tensor[(192), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][34] /* ty=Tensor[(192), float32] */, strides=[2, 2], padding=[0, 0, 1, 1], groups=192, channels=192, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 192, 64, 64), int32] */;
  %31 = nn.bias_add(%30, meta[relay.Constant][35] /* ty=Tensor[(192), int32] */) /* ty=Tensor[(1, 192, 64, 64), int32] */;
  %32 = qnn.quantize(meta[relay.Constant][36] /* ty=Tensor[(1, 192, 1, 1), float32] */, meta[relay.Constant][37] /* ty=Tensor[(192), float32] */, meta[relay.Constant][38] /* ty=Tensor[(192), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 192, 1, 1), int32] */;
  %33 = maximum(%31, %32) /* ty=Tensor[(1, 192, 64, 64), int32] */;
  %34 = qnn.quantize(meta[relay.Constant][39] /* ty=Tensor[(1, 192, 1, 1), float32] */, meta[relay.Constant][37] /* ty=Tensor[(192), float32] */, meta[relay.Constant][38] /* ty=Tensor[(192), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 192, 1, 1), int32] */;
  %35 = minimum(%33, %34) /* ty=Tensor[(1, 192, 64, 64), int32] */;
  %36 = qnn.requantize(%35, meta[relay.Constant][37] /* ty=Tensor[(192), float32] */, meta[relay.Constant][38] /* ty=Tensor[(192), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 192, 64, 64), int8] */;
  %37 = qnn.conv2d(%36, meta[relay.Constant][40] /* ty=Tensor[(40, 192, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][41] /* ty=Tensor[(40), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][42] /* ty=Tensor[(40), float32] */, padding=[0, 0, 0, 0], channels=40, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 40, 64, 64), int32] */;
  %38 = nn.bias_add(%37, meta[relay.Constant][43] /* ty=Tensor[(40), int32] */) /* ty=Tensor[(1, 40, 64, 64), int32] */;
  %39 = qnn.requantize(%38, meta[relay.Constant][44] /* ty=Tensor[(40), float32] */, meta[relay.Constant][45] /* ty=Tensor[(40), int32] */, 0.032934f /* ty=float32 */, -4 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 40, 64, 64), int8] */;
  %40 = qnn.conv2d(%39, meta[relay.Constant][46] /* ty=Tensor[(240, 40, 1, 1), int8] */, -4 /* ty=int32 */, meta[relay.Constant][47] /* ty=Tensor[(240), int32] */, 0.032934f /* ty=float32 */, meta[relay.Constant][48] /* ty=Tensor[(240), float32] */, padding=[0, 0, 0, 0], channels=240, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 240, 64, 64), int32] */;
  %41 = nn.bias_add(%40, meta[relay.Constant][49] /* ty=Tensor[(240), int32] */) /* ty=Tensor[(1, 240, 64, 64), int32] */;
  %42 = qnn.quantize(meta[relay.Constant][50] /* ty=Tensor[(1, 240, 1, 1), float32] */, meta[relay.Constant][51] /* ty=Tensor[(240), float32] */, meta[relay.Constant][52] /* ty=Tensor[(240), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 240, 1, 1), int32] */;
  %43 = maximum(%41, %42) /* ty=Tensor[(1, 240, 64, 64), int32] */;
  %44 = qnn.quantize(meta[relay.Constant][53] /* ty=Tensor[(1, 240, 1, 1), float32] */, meta[relay.Constant][51] /* ty=Tensor[(240), float32] */, meta[relay.Constant][52] /* ty=Tensor[(240), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 240, 1, 1), int32] */;
  %45 = minimum(%43, %44) /* ty=Tensor[(1, 240, 64, 64), int32] */;
  %46 = qnn.requantize(%45, meta[relay.Constant][51] /* ty=Tensor[(240), float32] */, meta[relay.Constant][52] /* ty=Tensor[(240), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 240, 64, 64), int8] */;
  %47 = qnn.conv2d(%46, meta[relay.Constant][54] /* ty=Tensor[(240, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][55] /* ty=Tensor[(240), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][56] /* ty=Tensor[(240), float32] */, padding=[1, 1, 1, 1], groups=240, channels=240, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 240, 64, 64), int32] */;
  %48 = nn.bias_add(%47, meta[relay.Constant][57] /* ty=Tensor[(240), int32] */) /* ty=Tensor[(1, 240, 64, 64), int32] */;
  %49 = qnn.quantize(meta[relay.Constant][58] /* ty=Tensor[(1, 240, 1, 1), float32] */, meta[relay.Constant][59] /* ty=Tensor[(240), float32] */, meta[relay.Constant][60] /* ty=Tensor[(240), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 240, 1, 1), int32] */;
  %50 = maximum(%48, %49) /* ty=Tensor[(1, 240, 64, 64), int32] */;
  %51 = qnn.quantize(meta[relay.Constant][61] /* ty=Tensor[(1, 240, 1, 1), float32] */, meta[relay.Constant][59] /* ty=Tensor[(240), float32] */, meta[relay.Constant][60] /* ty=Tensor[(240), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 240, 1, 1), int32] */;
  %52 = minimum(%50, %51) /* ty=Tensor[(1, 240, 64, 64), int32] */;
  %53 = qnn.requantize(%52, meta[relay.Constant][59] /* ty=Tensor[(240), float32] */, meta[relay.Constant][60] /* ty=Tensor[(240), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 240, 64, 64), int8] */;
  %54 = qnn.conv2d(%53, meta[relay.Constant][62] /* ty=Tensor[(40, 240, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][63] /* ty=Tensor[(40), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][64] /* ty=Tensor[(40), float32] */, padding=[0, 0, 0, 0], channels=40, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 40, 64, 64), int32] */;
  %55 = nn.bias_add(%54, meta[relay.Constant][65] /* ty=Tensor[(40), int32] */) /* ty=Tensor[(1, 40, 64, 64), int32] */;
  %56 = qnn.requantize(%55, meta[relay.Constant][66] /* ty=Tensor[(40), float32] */, meta[relay.Constant][67] /* ty=Tensor[(40), int32] */, 0.0362254f /* ty=float32 */, -3 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 40, 64, 64), int8] */;
  %57 = qnn.add(%39, %56, 0.032934f /* ty=float32 */, -4 /* ty=int32 */, 0.0362254f /* ty=float32 */, -3 /* ty=int32 */, 0.0575621f /* ty=float32 */, -16 /* ty=int32 */) /* ty=Tensor[(1, 40, 64, 64), int8] */;
  %58 = qnn.conv2d(%57, meta[relay.Constant][68] /* ty=Tensor[(240, 40, 1, 1), int8] */, -16 /* ty=int32 */, meta[relay.Constant][69] /* ty=Tensor[(240), int32] */, 0.0575621f /* ty=float32 */, meta[relay.Constant][70] /* ty=Tensor[(240), float32] */, padding=[0, 0, 0, 0], channels=240, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 240, 64, 64), int32] */;
  %59 = nn.bias_add(%58, meta[relay.Constant][71] /* ty=Tensor[(240), int32] */) /* ty=Tensor[(1, 240, 64, 64), int32] */;
  %60 = qnn.quantize(meta[relay.Constant][72] /* ty=Tensor[(1, 240, 1, 1), float32] */, meta[relay.Constant][73] /* ty=Tensor[(240), float32] */, meta[relay.Constant][74] /* ty=Tensor[(240), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 240, 1, 1), int32] */;
  %61 = maximum(%59, %60) /* ty=Tensor[(1, 240, 64, 64), int32] */;
  %62 = qnn.quantize(meta[relay.Constant][75] /* ty=Tensor[(1, 240, 1, 1), float32] */, meta[relay.Constant][73] /* ty=Tensor[(240), float32] */, meta[relay.Constant][74] /* ty=Tensor[(240), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 240, 1, 1), int32] */;
  %63 = minimum(%61, %62) /* ty=Tensor[(1, 240, 64, 64), int32] */;
  %64 = qnn.requantize(%63, meta[relay.Constant][73] /* ty=Tensor[(240), float32] */, meta[relay.Constant][74] /* ty=Tensor[(240), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 240, 64, 64), int8] */;
  %65 = qnn.conv2d(%64, meta[relay.Constant][76] /* ty=Tensor[(240, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][77] /* ty=Tensor[(240), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][78] /* ty=Tensor[(240), float32] */, strides=[2, 2], padding=[0, 0, 1, 1], groups=240, channels=240, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 240, 32, 32), int32] */;
  %66 = nn.bias_add(%65, meta[relay.Constant][79] /* ty=Tensor[(240), int32] */) /* ty=Tensor[(1, 240, 32, 32), int32] */;
  %67 = qnn.quantize(meta[relay.Constant][80] /* ty=Tensor[(1, 240, 1, 1), float32] */, meta[relay.Constant][81] /* ty=Tensor[(240), float32] */, meta[relay.Constant][82] /* ty=Tensor[(240), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 240, 1, 1), int32] */;
  %68 = maximum(%66, %67) /* ty=Tensor[(1, 240, 32, 32), int32] */;
  %69 = qnn.quantize(meta[relay.Constant][83] /* ty=Tensor[(1, 240, 1, 1), float32] */, meta[relay.Constant][81] /* ty=Tensor[(240), float32] */, meta[relay.Constant][82] /* ty=Tensor[(240), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 240, 1, 1), int32] */;
  %70 = minimum(%68, %69) /* ty=Tensor[(1, 240, 32, 32), int32] */;
  %71 = qnn.requantize(%70, meta[relay.Constant][81] /* ty=Tensor[(240), float32] */, meta[relay.Constant][82] /* ty=Tensor[(240), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 240, 32, 32), int8] */;
  %72 = qnn.conv2d(%71, meta[relay.Constant][84] /* ty=Tensor[(56, 240, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][85] /* ty=Tensor[(56), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][86] /* ty=Tensor[(56), float32] */, padding=[0, 0, 0, 0], channels=56, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 56, 32, 32), int32] */;
  %73 = nn.bias_add(%72, meta[relay.Constant][87] /* ty=Tensor[(56), int32] */) /* ty=Tensor[(1, 56, 32, 32), int32] */;
  %74 = qnn.requantize(%73, meta[relay.Constant][88] /* ty=Tensor[(56), float32] */, meta[relay.Constant][89] /* ty=Tensor[(56), int32] */, 0.0268897f /* ty=float32 */, -9 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 56, 32, 32), int8] */;
  %75 = qnn.conv2d(%74, meta[relay.Constant][90] /* ty=Tensor[(336, 56, 1, 1), int8] */, -9 /* ty=int32 */, meta[relay.Constant][91] /* ty=Tensor[(336), int32] */, 0.0268897f /* ty=float32 */, meta[relay.Constant][92] /* ty=Tensor[(336), float32] */, padding=[0, 0, 0, 0], channels=336, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %76 = nn.bias_add(%75, meta[relay.Constant][93] /* ty=Tensor[(336), int32] */) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %77 = qnn.quantize(meta[relay.Constant][94] /* ty=Tensor[(1, 336, 1, 1), float32] */, meta[relay.Constant][95] /* ty=Tensor[(336), float32] */, meta[relay.Constant][96] /* ty=Tensor[(336), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 336, 1, 1), int32] */;
  %78 = maximum(%76, %77) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %79 = qnn.quantize(meta[relay.Constant][97] /* ty=Tensor[(1, 336, 1, 1), float32] */, meta[relay.Constant][95] /* ty=Tensor[(336), float32] */, meta[relay.Constant][96] /* ty=Tensor[(336), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 336, 1, 1), int32] */;
  %80 = minimum(%78, %79) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %81 = qnn.requantize(%80, meta[relay.Constant][95] /* ty=Tensor[(336), float32] */, meta[relay.Constant][96] /* ty=Tensor[(336), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 336, 32, 32), int8] */;
  %82 = qnn.conv2d(%81, meta[relay.Constant][98] /* ty=Tensor[(336, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][99] /* ty=Tensor[(336), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][100] /* ty=Tensor[(336), float32] */, padding=[1, 1, 1, 1], groups=336, channels=336, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %83 = nn.bias_add(%82, meta[relay.Constant][101] /* ty=Tensor[(336), int32] */) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %84 = qnn.quantize(meta[relay.Constant][102] /* ty=Tensor[(1, 336, 1, 1), float32] */, meta[relay.Constant][103] /* ty=Tensor[(336), float32] */, meta[relay.Constant][104] /* ty=Tensor[(336), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 336, 1, 1), int32] */;
  %85 = maximum(%83, %84) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %86 = qnn.quantize(meta[relay.Constant][105] /* ty=Tensor[(1, 336, 1, 1), float32] */, meta[relay.Constant][103] /* ty=Tensor[(336), float32] */, meta[relay.Constant][104] /* ty=Tensor[(336), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 336, 1, 1), int32] */;
  %87 = minimum(%85, %86) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %88 = qnn.requantize(%87, meta[relay.Constant][103] /* ty=Tensor[(336), float32] */, meta[relay.Constant][104] /* ty=Tensor[(336), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 336, 32, 32), int8] */;
  %89 = qnn.conv2d(%88, meta[relay.Constant][106] /* ty=Tensor[(56, 336, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][107] /* ty=Tensor[(56), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][108] /* ty=Tensor[(56), float32] */, padding=[0, 0, 0, 0], channels=56, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 56, 32, 32), int32] */;
  %90 = nn.bias_add(%89, meta[relay.Constant][109] /* ty=Tensor[(56), int32] */) /* ty=Tensor[(1, 56, 32, 32), int32] */;
  %91 = qnn.requantize(%90, meta[relay.Constant][110] /* ty=Tensor[(56), float32] */, meta[relay.Constant][111] /* ty=Tensor[(56), int32] */, 0.0256578f /* ty=float32 */, 4 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 56, 32, 32), int8] */;
  %92 = qnn.add(%74, %91, 0.0268897f /* ty=float32 */, -9 /* ty=int32 */, 0.0256578f /* ty=float32 */, 4 /* ty=int32 */, 0.0466993f /* ty=float32 */, -2 /* ty=int32 */) /* ty=Tensor[(1, 56, 32, 32), int8] */;
  %93 = qnn.conv2d(%92, meta[relay.Constant][112] /* ty=Tensor[(336, 56, 1, 1), int8] */, -2 /* ty=int32 */, meta[relay.Constant][113] /* ty=Tensor[(336), int32] */, 0.0466993f /* ty=float32 */, meta[relay.Constant][114] /* ty=Tensor[(336), float32] */, padding=[0, 0, 0, 0], channels=336, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %94 = nn.bias_add(%93, meta[relay.Constant][115] /* ty=Tensor[(336), int32] */) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %95 = qnn.quantize(meta[relay.Constant][116] /* ty=Tensor[(1, 336, 1, 1), float32] */, meta[relay.Constant][117] /* ty=Tensor[(336), float32] */, meta[relay.Constant][118] /* ty=Tensor[(336), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 336, 1, 1), int32] */;
  %96 = maximum(%94, %95) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %97 = qnn.quantize(meta[relay.Constant][119] /* ty=Tensor[(1, 336, 1, 1), float32] */, meta[relay.Constant][117] /* ty=Tensor[(336), float32] */, meta[relay.Constant][118] /* ty=Tensor[(336), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 336, 1, 1), int32] */;
  %98 = minimum(%96, %97) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %99 = qnn.requantize(%98, meta[relay.Constant][117] /* ty=Tensor[(336), float32] */, meta[relay.Constant][118] /* ty=Tensor[(336), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 336, 32, 32), int8] */;
  %100 = qnn.conv2d(%99, meta[relay.Constant][120] /* ty=Tensor[(336, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][121] /* ty=Tensor[(336), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][122] /* ty=Tensor[(336), float32] */, padding=[1, 1, 1, 1], groups=336, channels=336, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %101 = nn.bias_add(%100, meta[relay.Constant][123] /* ty=Tensor[(336), int32] */) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %102 = qnn.quantize(meta[relay.Constant][124] /* ty=Tensor[(1, 336, 1, 1), float32] */, meta[relay.Constant][125] /* ty=Tensor[(336), float32] */, meta[relay.Constant][126] /* ty=Tensor[(336), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 336, 1, 1), int32] */;
  %103 = maximum(%101, %102) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %104 = qnn.quantize(meta[relay.Constant][127] /* ty=Tensor[(1, 336, 1, 1), float32] */, meta[relay.Constant][125] /* ty=Tensor[(336), float32] */, meta[relay.Constant][126] /* ty=Tensor[(336), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 336, 1, 1), int32] */;
  %105 = minimum(%103, %104) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %106 = qnn.requantize(%105, meta[relay.Constant][125] /* ty=Tensor[(336), float32] */, meta[relay.Constant][126] /* ty=Tensor[(336), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 336, 32, 32), int8] */;
  %107 = qnn.conv2d(%106, meta[relay.Constant][128] /* ty=Tensor[(56, 336, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][129] /* ty=Tensor[(56), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][130] /* ty=Tensor[(56), float32] */, padding=[0, 0, 0, 0], channels=56, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 56, 32, 32), int32] */;
  %108 = nn.bias_add(%107, meta[relay.Constant][131] /* ty=Tensor[(56), int32] */) /* ty=Tensor[(1, 56, 32, 32), int32] */;
  %109 = qnn.requantize(%108, meta[relay.Constant][132] /* ty=Tensor[(56), float32] */, meta[relay.Constant][133] /* ty=Tensor[(56), int32] */, 0.0470043f /* ty=float32 */, -8 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 56, 32, 32), int8] */;
  %110 = qnn.add(%92, %109, 0.0466993f /* ty=float32 */, -2 /* ty=int32 */, 0.0470043f /* ty=float32 */, -8 /* ty=int32 */, 0.0647469f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 56, 32, 32), int8] */;
  %111 = qnn.conv2d(%110, meta[relay.Constant][134] /* ty=Tensor[(336, 56, 1, 1), int8] */, 0 /* ty=int32 */, meta[relay.Constant][135] /* ty=Tensor[(336), int32] */, 0.0647469f /* ty=float32 */, meta[relay.Constant][136] /* ty=Tensor[(336), float32] */, padding=[0, 0, 0, 0], channels=336, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %112 = nn.bias_add(%111, meta[relay.Constant][137] /* ty=Tensor[(336), int32] */) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %113 = qnn.quantize(meta[relay.Constant][138] /* ty=Tensor[(1, 336, 1, 1), float32] */, meta[relay.Constant][139] /* ty=Tensor[(336), float32] */, meta[relay.Constant][140] /* ty=Tensor[(336), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 336, 1, 1), int32] */;
  %114 = maximum(%112, %113) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %115 = qnn.quantize(meta[relay.Constant][141] /* ty=Tensor[(1, 336, 1, 1), float32] */, meta[relay.Constant][139] /* ty=Tensor[(336), float32] */, meta[relay.Constant][140] /* ty=Tensor[(336), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 336, 1, 1), int32] */;
  %116 = minimum(%114, %115) /* ty=Tensor[(1, 336, 32, 32), int32] */;
  %117 = qnn.requantize(%116, meta[relay.Constant][139] /* ty=Tensor[(336), float32] */, meta[relay.Constant][140] /* ty=Tensor[(336), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 336, 32, 32), int8] */;
  %118 = qnn.conv2d(%117, meta[relay.Constant][142] /* ty=Tensor[(336, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][143] /* ty=Tensor[(336), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][144] /* ty=Tensor[(336), float32] */, strides=[2, 2], padding=[0, 0, 1, 1], groups=336, channels=336, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 336, 16, 16), int32] */;
  %119 = nn.bias_add(%118, meta[relay.Constant][145] /* ty=Tensor[(336), int32] */) /* ty=Tensor[(1, 336, 16, 16), int32] */;
  %120 = qnn.quantize(meta[relay.Constant][146] /* ty=Tensor[(1, 336, 1, 1), float32] */, meta[relay.Constant][147] /* ty=Tensor[(336), float32] */, meta[relay.Constant][148] /* ty=Tensor[(336), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 336, 1, 1), int32] */;
  %121 = maximum(%119, %120) /* ty=Tensor[(1, 336, 16, 16), int32] */;
  %122 = qnn.quantize(meta[relay.Constant][149] /* ty=Tensor[(1, 336, 1, 1), float32] */, meta[relay.Constant][147] /* ty=Tensor[(336), float32] */, meta[relay.Constant][148] /* ty=Tensor[(336), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 336, 1, 1), int32] */;
  %123 = minimum(%121, %122) /* ty=Tensor[(1, 336, 16, 16), int32] */;
  %124 = qnn.requantize(%123, meta[relay.Constant][147] /* ty=Tensor[(336), float32] */, meta[relay.Constant][148] /* ty=Tensor[(336), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 336, 16, 16), int8] */;
  %125 = qnn.conv2d(%124, meta[relay.Constant][150] /* ty=Tensor[(112, 336, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][151] /* ty=Tensor[(112), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][152] /* ty=Tensor[(112), float32] */, padding=[0, 0, 0, 0], channels=112, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 112, 16, 16), int32] */;
  %126 = nn.bias_add(%125, meta[relay.Constant][153] /* ty=Tensor[(112), int32] */) /* ty=Tensor[(1, 112, 16, 16), int32] */;
  %127 = qnn.requantize(%126, meta[relay.Constant][154] /* ty=Tensor[(112), float32] */, meta[relay.Constant][155] /* ty=Tensor[(112), int32] */, 0.0806844f /* ty=float32 */, -18 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 112, 16, 16), int8] */;
  %128 = qnn.conv2d(%127, meta[relay.Constant][156] /* ty=Tensor[(672, 112, 1, 1), int8] */, -18 /* ty=int32 */, meta[relay.Constant][157] /* ty=Tensor[(672), int32] */, 0.0806844f /* ty=float32 */, meta[relay.Constant][158] /* ty=Tensor[(672), float32] */, padding=[0, 0, 0, 0], channels=672, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %129 = nn.bias_add(%128, meta[relay.Constant][159] /* ty=Tensor[(672), int32] */) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %130 = qnn.quantize(meta[relay.Constant][160] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][161] /* ty=Tensor[(672), float32] */, meta[relay.Constant][162] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %131 = maximum(%129, %130) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %132 = qnn.quantize(meta[relay.Constant][163] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][161] /* ty=Tensor[(672), float32] */, meta[relay.Constant][162] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %133 = minimum(%131, %132) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %134 = qnn.requantize(%133, meta[relay.Constant][161] /* ty=Tensor[(672), float32] */, meta[relay.Constant][162] /* ty=Tensor[(672), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 672, 16, 16), int8] */;
  %135 = qnn.conv2d(%134, meta[relay.Constant][164] /* ty=Tensor[(672, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][165] /* ty=Tensor[(672), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][166] /* ty=Tensor[(672), float32] */, padding=[1, 1, 1, 1], groups=672, channels=672, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %136 = nn.bias_add(%135, meta[relay.Constant][167] /* ty=Tensor[(672), int32] */) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %137 = qnn.quantize(meta[relay.Constant][168] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][169] /* ty=Tensor[(672), float32] */, meta[relay.Constant][170] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %138 = maximum(%136, %137) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %139 = qnn.quantize(meta[relay.Constant][171] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][169] /* ty=Tensor[(672), float32] */, meta[relay.Constant][170] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %140 = minimum(%138, %139) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %141 = qnn.requantize(%140, meta[relay.Constant][169] /* ty=Tensor[(672), float32] */, meta[relay.Constant][170] /* ty=Tensor[(672), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 672, 16, 16), int8] */;
  %142 = qnn.conv2d(%141, meta[relay.Constant][172] /* ty=Tensor[(112, 672, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][173] /* ty=Tensor[(112), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][174] /* ty=Tensor[(112), float32] */, padding=[0, 0, 0, 0], channels=112, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 112, 16, 16), int32] */;
  %143 = nn.bias_add(%142, meta[relay.Constant][175] /* ty=Tensor[(112), int32] */) /* ty=Tensor[(1, 112, 16, 16), int32] */;
  %144 = qnn.requantize(%143, meta[relay.Constant][176] /* ty=Tensor[(112), float32] */, meta[relay.Constant][177] /* ty=Tensor[(112), int32] */, 0.0557437f /* ty=float32 */, 9 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 112, 16, 16), int8] */;
  %145 = qnn.add(%127, %144, 0.0806844f /* ty=float32 */, -18 /* ty=int32 */, 0.0557437f /* ty=float32 */, 9 /* ty=int32 */, 0.0995401f /* ty=float32 */, -13 /* ty=int32 */) /* ty=Tensor[(1, 112, 16, 16), int8] */;
  %146 = qnn.conv2d(%145, meta[relay.Constant][178] /* ty=Tensor[(672, 112, 1, 1), int8] */, -13 /* ty=int32 */, meta[relay.Constant][179] /* ty=Tensor[(672), int32] */, 0.0995401f /* ty=float32 */, meta[relay.Constant][180] /* ty=Tensor[(672), float32] */, padding=[0, 0, 0, 0], channels=672, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %147 = nn.bias_add(%146, meta[relay.Constant][181] /* ty=Tensor[(672), int32] */) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %148 = qnn.quantize(meta[relay.Constant][182] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][183] /* ty=Tensor[(672), float32] */, meta[relay.Constant][184] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %149 = maximum(%147, %148) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %150 = qnn.quantize(meta[relay.Constant][185] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][183] /* ty=Tensor[(672), float32] */, meta[relay.Constant][184] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %151 = minimum(%149, %150) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %152 = qnn.requantize(%151, meta[relay.Constant][183] /* ty=Tensor[(672), float32] */, meta[relay.Constant][184] /* ty=Tensor[(672), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 672, 16, 16), int8] */;
  %153 = qnn.conv2d(%152, meta[relay.Constant][186] /* ty=Tensor[(672, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][187] /* ty=Tensor[(672), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][188] /* ty=Tensor[(672), float32] */, padding=[1, 1, 1, 1], groups=672, channels=672, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %154 = nn.bias_add(%153, meta[relay.Constant][189] /* ty=Tensor[(672), int32] */) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %155 = qnn.quantize(meta[relay.Constant][190] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][191] /* ty=Tensor[(672), float32] */, meta[relay.Constant][192] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %156 = maximum(%154, %155) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %157 = qnn.quantize(meta[relay.Constant][193] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][191] /* ty=Tensor[(672), float32] */, meta[relay.Constant][192] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %158 = minimum(%156, %157) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %159 = qnn.requantize(%158, meta[relay.Constant][191] /* ty=Tensor[(672), float32] */, meta[relay.Constant][192] /* ty=Tensor[(672), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 672, 16, 16), int8] */;
  %160 = qnn.conv2d(%159, meta[relay.Constant][194] /* ty=Tensor[(112, 672, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][195] /* ty=Tensor[(112), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][196] /* ty=Tensor[(112), float32] */, padding=[0, 0, 0, 0], channels=112, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 112, 16, 16), int32] */;
  %161 = nn.bias_add(%160, meta[relay.Constant][197] /* ty=Tensor[(112), int32] */) /* ty=Tensor[(1, 112, 16, 16), int32] */;
  %162 = qnn.requantize(%161, meta[relay.Constant][198] /* ty=Tensor[(112), float32] */, meta[relay.Constant][199] /* ty=Tensor[(112), int32] */, 0.0690793f /* ty=float32 */, 6 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 112, 16, 16), int8] */;
  %163 = qnn.add(%145, %162, 0.0995401f /* ty=float32 */, -13 /* ty=int32 */, 0.0690793f /* ty=float32 */, 6 /* ty=int32 */, 0.111631f /* ty=float32 */, -1 /* ty=int32 */) /* ty=Tensor[(1, 112, 16, 16), int8] */;
  %164 = qnn.conv2d(%163, meta[relay.Constant][200] /* ty=Tensor[(672, 112, 1, 1), int8] */, -1 /* ty=int32 */, meta[relay.Constant][201] /* ty=Tensor[(672), int32] */, 0.111631f /* ty=float32 */, meta[relay.Constant][202] /* ty=Tensor[(672), float32] */, padding=[0, 0, 0, 0], channels=672, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %165 = nn.bias_add(%164, meta[relay.Constant][203] /* ty=Tensor[(672), int32] */) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %166 = qnn.quantize(meta[relay.Constant][204] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][205] /* ty=Tensor[(672), float32] */, meta[relay.Constant][206] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %167 = maximum(%165, %166) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %168 = qnn.quantize(meta[relay.Constant][207] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][205] /* ty=Tensor[(672), float32] */, meta[relay.Constant][206] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %169 = minimum(%167, %168) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %170 = qnn.requantize(%169, meta[relay.Constant][205] /* ty=Tensor[(672), float32] */, meta[relay.Constant][206] /* ty=Tensor[(672), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 672, 16, 16), int8] */;
  %171 = qnn.conv2d(%170, meta[relay.Constant][208] /* ty=Tensor[(672, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][209] /* ty=Tensor[(672), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][210] /* ty=Tensor[(672), float32] */, padding=[1, 1, 1, 1], groups=672, channels=672, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %172 = nn.bias_add(%171, meta[relay.Constant][211] /* ty=Tensor[(672), int32] */) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %173 = qnn.quantize(meta[relay.Constant][212] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][213] /* ty=Tensor[(672), float32] */, meta[relay.Constant][214] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %174 = maximum(%172, %173) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %175 = qnn.quantize(meta[relay.Constant][215] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][213] /* ty=Tensor[(672), float32] */, meta[relay.Constant][214] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %176 = minimum(%174, %175) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %177 = qnn.requantize(%176, meta[relay.Constant][213] /* ty=Tensor[(672), float32] */, meta[relay.Constant][214] /* ty=Tensor[(672), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 672, 16, 16), int8] */;
  %178 = qnn.conv2d(%177, meta[relay.Constant][216] /* ty=Tensor[(112, 672, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][217] /* ty=Tensor[(112), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][218] /* ty=Tensor[(112), float32] */, padding=[0, 0, 0, 0], channels=112, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 112, 16, 16), int32] */;
  %179 = nn.bias_add(%178, meta[relay.Constant][219] /* ty=Tensor[(112), int32] */) /* ty=Tensor[(1, 112, 16, 16), int32] */;
  %180 = qnn.requantize(%179, meta[relay.Constant][220] /* ty=Tensor[(112), float32] */, meta[relay.Constant][221] /* ty=Tensor[(112), int32] */, 0.107376f /* ty=float32 */, 4 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 112, 16, 16), int8] */;
  %181 = qnn.add(%163, %180, 0.111631f /* ty=float32 */, -1 /* ty=int32 */, 0.107376f /* ty=float32 */, 4 /* ty=int32 */, 0.17098f /* ty=float32 */, 2 /* ty=int32 */) /* ty=Tensor[(1, 112, 16, 16), int8] */;
  %182 = qnn.conv2d(%181, meta[relay.Constant][222] /* ty=Tensor[(672, 112, 1, 1), int8] */, 2 /* ty=int32 */, meta[relay.Constant][223] /* ty=Tensor[(672), int32] */, 0.17098f /* ty=float32 */, meta[relay.Constant][224] /* ty=Tensor[(672), float32] */, padding=[0, 0, 0, 0], channels=672, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %183 = nn.bias_add(%182, meta[relay.Constant][225] /* ty=Tensor[(672), int32] */) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %184 = qnn.quantize(meta[relay.Constant][226] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][227] /* ty=Tensor[(672), float32] */, meta[relay.Constant][228] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %185 = maximum(%183, %184) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %186 = qnn.quantize(meta[relay.Constant][229] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][227] /* ty=Tensor[(672), float32] */, meta[relay.Constant][228] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %187 = minimum(%185, %186) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %188 = qnn.requantize(%187, meta[relay.Constant][227] /* ty=Tensor[(672), float32] */, meta[relay.Constant][228] /* ty=Tensor[(672), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 672, 16, 16), int8] */;
  %189 = qnn.conv2d(%188, meta[relay.Constant][230] /* ty=Tensor[(672, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][231] /* ty=Tensor[(672), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][232] /* ty=Tensor[(672), float32] */, padding=[1, 1, 1, 1], groups=672, channels=672, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %190 = nn.bias_add(%189, meta[relay.Constant][233] /* ty=Tensor[(672), int32] */) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %191 = qnn.quantize(meta[relay.Constant][234] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][235] /* ty=Tensor[(672), float32] */, meta[relay.Constant][236] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %192 = maximum(%190, %191) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %193 = qnn.quantize(meta[relay.Constant][237] /* ty=Tensor[(1, 672, 1, 1), float32] */, meta[relay.Constant][235] /* ty=Tensor[(672), float32] */, meta[relay.Constant][236] /* ty=Tensor[(672), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 672, 1, 1), int32] */;
  %194 = minimum(%192, %193) /* ty=Tensor[(1, 672, 16, 16), int32] */;
  %195 = qnn.requantize(%194, meta[relay.Constant][235] /* ty=Tensor[(672), float32] */, meta[relay.Constant][236] /* ty=Tensor[(672), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 672, 16, 16), int8] */;
  %196 = qnn.conv2d(%195, meta[relay.Constant][238] /* ty=Tensor[(168, 672, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][239] /* ty=Tensor[(168), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][240] /* ty=Tensor[(168), float32] */, padding=[0, 0, 0, 0], channels=168, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 168, 16, 16), int32] */;
  %197 = nn.bias_add(%196, meta[relay.Constant][241] /* ty=Tensor[(168), int32] */) /* ty=Tensor[(1, 168, 16, 16), int32] */;
  %198 = qnn.requantize(%197, meta[relay.Constant][242] /* ty=Tensor[(168), float32] */, meta[relay.Constant][243] /* ty=Tensor[(168), int32] */, 0.160035f /* ty=float32 */, 13 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 168, 16, 16), int8] */;
  %199 = qnn.conv2d(%198, meta[relay.Constant][244] /* ty=Tensor[(1008, 168, 1, 1), int8] */, 13 /* ty=int32 */, meta[relay.Constant][245] /* ty=Tensor[(1008), int32] */, 0.160035f /* ty=float32 */, meta[relay.Constant][246] /* ty=Tensor[(1008), float32] */, padding=[0, 0, 0, 0], channels=1008, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %200 = nn.bias_add(%199, meta[relay.Constant][247] /* ty=Tensor[(1008), int32] */) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %201 = qnn.quantize(meta[relay.Constant][248] /* ty=Tensor[(1, 1008, 1, 1), float32] */, meta[relay.Constant][249] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][250] /* ty=Tensor[(1008), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1008, 1, 1), int32] */;
  %202 = maximum(%200, %201) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %203 = qnn.quantize(meta[relay.Constant][251] /* ty=Tensor[(1, 1008, 1, 1), float32] */, meta[relay.Constant][249] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][250] /* ty=Tensor[(1008), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1008, 1, 1), int32] */;
  %204 = minimum(%202, %203) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %205 = qnn.requantize(%204, meta[relay.Constant][249] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][250] /* ty=Tensor[(1008), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1008, 16, 16), int8] */;
  %206 = qnn.conv2d(%205, meta[relay.Constant][252] /* ty=Tensor[(1008, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][253] /* ty=Tensor[(1008), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][254] /* ty=Tensor[(1008), float32] */, padding=[1, 1, 1, 1], groups=1008, channels=1008, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %207 = nn.bias_add(%206, meta[relay.Constant][255] /* ty=Tensor[(1008), int32] */) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %208 = qnn.quantize(meta[relay.Constant][256] /* ty=Tensor[(1, 1008, 1, 1), float32] */, meta[relay.Constant][257] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][258] /* ty=Tensor[(1008), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1008, 1, 1), int32] */;
  %209 = maximum(%207, %208) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %210 = qnn.quantize(meta[relay.Constant][259] /* ty=Tensor[(1, 1008, 1, 1), float32] */, meta[relay.Constant][257] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][258] /* ty=Tensor[(1008), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1008, 1, 1), int32] */;
  %211 = minimum(%209, %210) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %212 = qnn.requantize(%211, meta[relay.Constant][257] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][258] /* ty=Tensor[(1008), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1008, 16, 16), int8] */;
  %213 = qnn.conv2d(%212, meta[relay.Constant][260] /* ty=Tensor[(168, 1008, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][261] /* ty=Tensor[(168), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][262] /* ty=Tensor[(168), float32] */, padding=[0, 0, 0, 0], channels=168, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 168, 16, 16), int32] */;
  %214 = nn.bias_add(%213, meta[relay.Constant][263] /* ty=Tensor[(168), int32] */) /* ty=Tensor[(1, 168, 16, 16), int32] */;
  %215 = qnn.requantize(%214, meta[relay.Constant][264] /* ty=Tensor[(168), float32] */, meta[relay.Constant][265] /* ty=Tensor[(168), int32] */, 0.144729f /* ty=float32 */, -4 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 168, 16, 16), int8] */;
  %216 = qnn.add(%198, %215, 0.160035f /* ty=float32 */, 13 /* ty=int32 */, 0.144729f /* ty=float32 */, -4 /* ty=int32 */, 0.246944f /* ty=float32 */, -7 /* ty=int32 */) /* ty=Tensor[(1, 168, 16, 16), int8] */;
  %217 = qnn.conv2d(%216, meta[relay.Constant][266] /* ty=Tensor[(1008, 168, 1, 1), int8] */, -7 /* ty=int32 */, meta[relay.Constant][267] /* ty=Tensor[(1008), int32] */, 0.246944f /* ty=float32 */, meta[relay.Constant][268] /* ty=Tensor[(1008), float32] */, padding=[0, 0, 0, 0], channels=1008, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %218 = nn.bias_add(%217, meta[relay.Constant][269] /* ty=Tensor[(1008), int32] */) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %219 = qnn.quantize(meta[relay.Constant][270] /* ty=Tensor[(1, 1008, 1, 1), float32] */, meta[relay.Constant][271] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][272] /* ty=Tensor[(1008), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1008, 1, 1), int32] */;
  %220 = maximum(%218, %219) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %221 = qnn.quantize(meta[relay.Constant][273] /* ty=Tensor[(1, 1008, 1, 1), float32] */, meta[relay.Constant][271] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][272] /* ty=Tensor[(1008), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1008, 1, 1), int32] */;
  %222 = minimum(%220, %221) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %223 = qnn.requantize(%222, meta[relay.Constant][271] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][272] /* ty=Tensor[(1008), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1008, 16, 16), int8] */;
  %224 = qnn.conv2d(%223, meta[relay.Constant][274] /* ty=Tensor[(1008, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][275] /* ty=Tensor[(1008), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][276] /* ty=Tensor[(1008), float32] */, padding=[1, 1, 1, 1], groups=1008, channels=1008, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %225 = nn.bias_add(%224, meta[relay.Constant][277] /* ty=Tensor[(1008), int32] */) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %226 = qnn.quantize(meta[relay.Constant][278] /* ty=Tensor[(1, 1008, 1, 1), float32] */, meta[relay.Constant][279] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][280] /* ty=Tensor[(1008), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1008, 1, 1), int32] */;
  %227 = maximum(%225, %226) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %228 = qnn.quantize(meta[relay.Constant][281] /* ty=Tensor[(1, 1008, 1, 1), float32] */, meta[relay.Constant][279] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][280] /* ty=Tensor[(1008), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1008, 1, 1), int32] */;
  %229 = minimum(%227, %228) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %230 = qnn.requantize(%229, meta[relay.Constant][279] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][280] /* ty=Tensor[(1008), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1008, 16, 16), int8] */;
  %231 = qnn.conv2d(%230, meta[relay.Constant][282] /* ty=Tensor[(168, 1008, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][283] /* ty=Tensor[(168), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][284] /* ty=Tensor[(168), float32] */, padding=[0, 0, 0, 0], channels=168, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 168, 16, 16), int32] */;
  %232 = nn.bias_add(%231, meta[relay.Constant][285] /* ty=Tensor[(168), int32] */) /* ty=Tensor[(1, 168, 16, 16), int32] */;
  %233 = qnn.requantize(%232, meta[relay.Constant][286] /* ty=Tensor[(168), float32] */, meta[relay.Constant][287] /* ty=Tensor[(168), int32] */, 0.272881f /* ty=float32 */, 19 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 168, 16, 16), int8] */;
  %234 = qnn.add(%216, %233, 0.246944f /* ty=float32 */, -7 /* ty=int32 */, 0.272881f /* ty=float32 */, 19 /* ty=int32 */, 0.334703f /* ty=float32 */, 3 /* ty=int32 */) /* ty=Tensor[(1, 168, 16, 16), int8] */;
  %235 = qnn.conv2d(%234, meta[relay.Constant][288] /* ty=Tensor[(1008, 168, 1, 1), int8] */, 3 /* ty=int32 */, meta[relay.Constant][289] /* ty=Tensor[(1008), int32] */, 0.334703f /* ty=float32 */, meta[relay.Constant][290] /* ty=Tensor[(1008), float32] */, padding=[0, 0, 0, 0], channels=1008, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %236 = nn.bias_add(%235, meta[relay.Constant][291] /* ty=Tensor[(1008), int32] */) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %237 = qnn.quantize(meta[relay.Constant][292] /* ty=Tensor[(1, 1008, 1, 1), float32] */, meta[relay.Constant][293] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][294] /* ty=Tensor[(1008), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1008, 1, 1), int32] */;
  %238 = maximum(%236, %237) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %239 = qnn.quantize(meta[relay.Constant][295] /* ty=Tensor[(1, 1008, 1, 1), float32] */, meta[relay.Constant][293] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][294] /* ty=Tensor[(1008), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1008, 1, 1), int32] */;
  %240 = minimum(%238, %239) /* ty=Tensor[(1, 1008, 16, 16), int32] */;
  %241 = qnn.requantize(%240, meta[relay.Constant][293] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][294] /* ty=Tensor[(1008), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1008, 16, 16), int8] */;
  %242 = qnn.conv2d(%241, meta[relay.Constant][296] /* ty=Tensor[(1008, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][297] /* ty=Tensor[(1008), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][298] /* ty=Tensor[(1008), float32] */, strides=[2, 2], padding=[0, 0, 1, 1], groups=1008, channels=1008, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 1008, 8, 8), int32] */;
  %243 = nn.bias_add(%242, meta[relay.Constant][299] /* ty=Tensor[(1008), int32] */) /* ty=Tensor[(1, 1008, 8, 8), int32] */;
  %244 = qnn.quantize(meta[relay.Constant][300] /* ty=Tensor[(1, 1008, 1, 1), float32] */, meta[relay.Constant][301] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][302] /* ty=Tensor[(1008), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1008, 1, 1), int32] */;
  %245 = maximum(%243, %244) /* ty=Tensor[(1, 1008, 8, 8), int32] */;
  %246 = qnn.quantize(meta[relay.Constant][303] /* ty=Tensor[(1, 1008, 1, 1), float32] */, meta[relay.Constant][301] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][302] /* ty=Tensor[(1008), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1008, 1, 1), int32] */;
  %247 = minimum(%245, %246) /* ty=Tensor[(1, 1008, 8, 8), int32] */;
  %248 = qnn.requantize(%247, meta[relay.Constant][301] /* ty=Tensor[(1008), float32] */, meta[relay.Constant][302] /* ty=Tensor[(1008), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1008, 8, 8), int8] */;
  %249 = qnn.conv2d(%248, meta[relay.Constant][304] /* ty=Tensor[(280, 1008, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][305] /* ty=Tensor[(280), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][306] /* ty=Tensor[(280), float32] */, padding=[0, 0, 0, 0], channels=280, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 280, 8, 8), int32] */;
  %250 = nn.bias_add(%249, meta[relay.Constant][307] /* ty=Tensor[(280), int32] */) /* ty=Tensor[(1, 280, 8, 8), int32] */;
  %251 = qnn.requantize(%250, meta[relay.Constant][308] /* ty=Tensor[(280), float32] */, meta[relay.Constant][309] /* ty=Tensor[(280), int32] */, 0.143718f /* ty=float32 */, 2 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 280, 8, 8), int8] */;
  %252 = qnn.conv2d(%251, meta[relay.Constant][310] /* ty=Tensor[(1680, 280, 1, 1), int8] */, 2 /* ty=int32 */, meta[relay.Constant][311] /* ty=Tensor[(1680), int32] */, 0.143718f /* ty=float32 */, meta[relay.Constant][312] /* ty=Tensor[(1680), float32] */, padding=[0, 0, 0, 0], channels=1680, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %253 = nn.bias_add(%252, meta[relay.Constant][313] /* ty=Tensor[(1680), int32] */) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %254 = qnn.quantize(meta[relay.Constant][314] /* ty=Tensor[(1, 1680, 1, 1), float32] */, meta[relay.Constant][315] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][316] /* ty=Tensor[(1680), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1680, 1, 1), int32] */;
  %255 = maximum(%253, %254) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %256 = qnn.quantize(meta[relay.Constant][317] /* ty=Tensor[(1, 1680, 1, 1), float32] */, meta[relay.Constant][315] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][316] /* ty=Tensor[(1680), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1680, 1, 1), int32] */;
  %257 = minimum(%255, %256) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %258 = qnn.requantize(%257, meta[relay.Constant][315] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][316] /* ty=Tensor[(1680), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1680, 8, 8), int8] */;
  %259 = qnn.conv2d(%258, meta[relay.Constant][318] /* ty=Tensor[(1680, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][319] /* ty=Tensor[(1680), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][320] /* ty=Tensor[(1680), float32] */, padding=[1, 1, 1, 1], groups=1680, channels=1680, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %260 = nn.bias_add(%259, meta[relay.Constant][321] /* ty=Tensor[(1680), int32] */) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %261 = qnn.quantize(meta[relay.Constant][322] /* ty=Tensor[(1, 1680, 1, 1), float32] */, meta[relay.Constant][323] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][324] /* ty=Tensor[(1680), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1680, 1, 1), int32] */;
  %262 = maximum(%260, %261) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %263 = qnn.quantize(meta[relay.Constant][325] /* ty=Tensor[(1, 1680, 1, 1), float32] */, meta[relay.Constant][323] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][324] /* ty=Tensor[(1680), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1680, 1, 1), int32] */;
  %264 = minimum(%262, %263) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %265 = qnn.requantize(%264, meta[relay.Constant][323] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][324] /* ty=Tensor[(1680), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1680, 8, 8), int8] */;
  %266 = qnn.conv2d(%265, meta[relay.Constant][326] /* ty=Tensor[(280, 1680, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][327] /* ty=Tensor[(280), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][328] /* ty=Tensor[(280), float32] */, padding=[0, 0, 0, 0], channels=280, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 280, 8, 8), int32] */;
  %267 = nn.bias_add(%266, meta[relay.Constant][329] /* ty=Tensor[(280), int32] */) /* ty=Tensor[(1, 280, 8, 8), int32] */;
  %268 = qnn.requantize(%267, meta[relay.Constant][330] /* ty=Tensor[(280), float32] */, meta[relay.Constant][331] /* ty=Tensor[(280), int32] */, 0.116397f /* ty=float32 */, 6 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 280, 8, 8), int8] */;
  %269 = qnn.add(%251, %268, 0.143718f /* ty=float32 */, 2 /* ty=int32 */, 0.116397f /* ty=float32 */, 6 /* ty=int32 */, 0.203799f /* ty=float32 */, 2 /* ty=int32 */) /* ty=Tensor[(1, 280, 8, 8), int8] */;
  %270 = qnn.conv2d(%269, meta[relay.Constant][332] /* ty=Tensor[(1680, 280, 1, 1), int8] */, 2 /* ty=int32 */, meta[relay.Constant][333] /* ty=Tensor[(1680), int32] */, 0.203799f /* ty=float32 */, meta[relay.Constant][334] /* ty=Tensor[(1680), float32] */, padding=[0, 0, 0, 0], channels=1680, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %271 = nn.bias_add(%270, meta[relay.Constant][335] /* ty=Tensor[(1680), int32] */) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %272 = qnn.quantize(meta[relay.Constant][336] /* ty=Tensor[(1, 1680, 1, 1), float32] */, meta[relay.Constant][337] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][338] /* ty=Tensor[(1680), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1680, 1, 1), int32] */;
  %273 = maximum(%271, %272) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %274 = qnn.quantize(meta[relay.Constant][339] /* ty=Tensor[(1, 1680, 1, 1), float32] */, meta[relay.Constant][337] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][338] /* ty=Tensor[(1680), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1680, 1, 1), int32] */;
  %275 = minimum(%273, %274) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %276 = qnn.requantize(%275, meta[relay.Constant][337] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][338] /* ty=Tensor[(1680), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1680, 8, 8), int8] */;
  %277 = qnn.conv2d(%276, meta[relay.Constant][340] /* ty=Tensor[(1680, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][341] /* ty=Tensor[(1680), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][342] /* ty=Tensor[(1680), float32] */, padding=[1, 1, 1, 1], groups=1680, channels=1680, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %278 = nn.bias_add(%277, meta[relay.Constant][343] /* ty=Tensor[(1680), int32] */) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %279 = qnn.quantize(meta[relay.Constant][344] /* ty=Tensor[(1, 1680, 1, 1), float32] */, meta[relay.Constant][345] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][346] /* ty=Tensor[(1680), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1680, 1, 1), int32] */;
  %280 = maximum(%278, %279) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %281 = qnn.quantize(meta[relay.Constant][347] /* ty=Tensor[(1, 1680, 1, 1), float32] */, meta[relay.Constant][345] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][346] /* ty=Tensor[(1680), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1680, 1, 1), int32] */;
  %282 = minimum(%280, %281) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %283 = qnn.requantize(%282, meta[relay.Constant][345] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][346] /* ty=Tensor[(1680), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1680, 8, 8), int8] */;
  %284 = qnn.conv2d(%283, meta[relay.Constant][348] /* ty=Tensor[(280, 1680, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][349] /* ty=Tensor[(280), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][350] /* ty=Tensor[(280), float32] */, padding=[0, 0, 0, 0], channels=280, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 280, 8, 8), int32] */;
  %285 = nn.bias_add(%284, meta[relay.Constant][351] /* ty=Tensor[(280), int32] */) /* ty=Tensor[(1, 280, 8, 8), int32] */;
  %286 = qnn.requantize(%285, meta[relay.Constant][352] /* ty=Tensor[(280), float32] */, meta[relay.Constant][353] /* ty=Tensor[(280), int32] */, 0.25502f /* ty=float32 */, -2 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 280, 8, 8), int8] */;
  %287 = qnn.add(%269, %286, 0.203799f /* ty=float32 */, 2 /* ty=int32 */, 0.25502f /* ty=float32 */, -2 /* ty=int32 */, 0.35483f /* ty=float32 */, 7 /* ty=int32 */) /* ty=Tensor[(1, 280, 8, 8), int8] */;
  %288 = qnn.conv2d(%287, meta[relay.Constant][354] /* ty=Tensor[(1680, 280, 1, 1), int8] */, 7 /* ty=int32 */, meta[relay.Constant][355] /* ty=Tensor[(1680), int32] */, 0.35483f /* ty=float32 */, meta[relay.Constant][356] /* ty=Tensor[(1680), float32] */, padding=[0, 0, 0, 0], channels=1680, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %289 = nn.bias_add(%288, meta[relay.Constant][357] /* ty=Tensor[(1680), int32] */) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %290 = qnn.quantize(meta[relay.Constant][358] /* ty=Tensor[(1, 1680, 1, 1), float32] */, meta[relay.Constant][359] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][360] /* ty=Tensor[(1680), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1680, 1, 1), int32] */;
  %291 = maximum(%289, %290) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %292 = qnn.quantize(meta[relay.Constant][361] /* ty=Tensor[(1, 1680, 1, 1), float32] */, meta[relay.Constant][359] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][360] /* ty=Tensor[(1680), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1680, 1, 1), int32] */;
  %293 = minimum(%291, %292) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %294 = qnn.requantize(%293, meta[relay.Constant][359] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][360] /* ty=Tensor[(1680), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1680, 8, 8), int8] */;
  %295 = qnn.conv2d(%294, meta[relay.Constant][362] /* ty=Tensor[(1680, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][363] /* ty=Tensor[(1680), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][364] /* ty=Tensor[(1680), float32] */, padding=[1, 1, 1, 1], groups=1680, channels=1680, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %296 = nn.bias_add(%295, meta[relay.Constant][365] /* ty=Tensor[(1680), int32] */) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %297 = qnn.quantize(meta[relay.Constant][366] /* ty=Tensor[(1, 1680, 1, 1), float32] */, meta[relay.Constant][367] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][368] /* ty=Tensor[(1680), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1680, 1, 1), int32] */;
  %298 = maximum(%296, %297) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %299 = qnn.quantize(meta[relay.Constant][369] /* ty=Tensor[(1, 1680, 1, 1), float32] */, meta[relay.Constant][367] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][368] /* ty=Tensor[(1680), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1680, 1, 1), int32] */;
  %300 = minimum(%298, %299) /* ty=Tensor[(1, 1680, 8, 8), int32] */;
  %301 = qnn.requantize(%300, meta[relay.Constant][367] /* ty=Tensor[(1680), float32] */, meta[relay.Constant][368] /* ty=Tensor[(1680), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1680, 8, 8), int8] */;
  %302 = qnn.conv2d(%301, meta[relay.Constant][370] /* ty=Tensor[(560, 1680, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][371] /* ty=Tensor[(560), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][372] /* ty=Tensor[(560), float32] */, padding=[0, 0, 0, 0], channels=560, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 560, 8, 8), int32] */;
  %303 = nn.bias_add(%302, meta[relay.Constant][373] /* ty=Tensor[(560), int32] */) /* ty=Tensor[(1, 560, 8, 8), int32] */;
  %304 = qnn.requantize(%303, meta[relay.Constant][374] /* ty=Tensor[(560), float32] */, meta[relay.Constant][375] /* ty=Tensor[(560), int32] */, 0.146431f /* ty=float32 */, 10 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 560, 8, 8), int8] */;
  %305 = qnn.conv2d(%304, meta[relay.Constant][376] /* ty=Tensor[(1280, 560, 1, 1), int8] */, 10 /* ty=int32 */, meta[relay.Constant][377] /* ty=Tensor[(1280), int32] */, 0.146431f /* ty=float32 */, meta[relay.Constant][378] /* ty=Tensor[(1280), float32] */, padding=[0, 0, 0, 0], channels=1280, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 1280, 8, 8), int32] */;
  %306 = nn.bias_add(%305, meta[relay.Constant][379] /* ty=Tensor[(1280), int32] */) /* ty=Tensor[(1, 1280, 8, 8), int32] */;
  %307 = qnn.quantize(meta[relay.Constant][380] /* ty=Tensor[(1, 1280, 1, 1), float32] */, meta[relay.Constant][381] /* ty=Tensor[(1280), float32] */, meta[relay.Constant][382] /* ty=Tensor[(1280), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1280, 1, 1), int32] */;
  %308 = maximum(%306, %307) /* ty=Tensor[(1, 1280, 8, 8), int32] */;
  %309 = qnn.quantize(meta[relay.Constant][383] /* ty=Tensor[(1, 1280, 1, 1), float32] */, meta[relay.Constant][381] /* ty=Tensor[(1280), float32] */, meta[relay.Constant][382] /* ty=Tensor[(1280), int32] */, out_dtype="int32", axis=1) /* ty=Tensor[(1, 1280, 1, 1), int32] */;
  %310 = minimum(%308, %309) /* ty=Tensor[(1, 1280, 8, 8), int32] */;
  %311 = qnn.requantize(%310, meta[relay.Constant][381] /* ty=Tensor[(1280), float32] */, meta[relay.Constant][382] /* ty=Tensor[(1280), int32] */, 0.0235294f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1280, 8, 8), int8] */;
  %312 = qnn.conv2d(%311, meta[relay.Constant][384] /* ty=Tensor[(64, 1280, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][385] /* ty=Tensor[(64), int32] */, 0.0235294f /* ty=float32 */, meta[relay.Constant][386] /* ty=Tensor[(64), float32] */, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 64, 8, 8), int32] */;
  %313 = nn.bias_add(%312, meta[relay.Constant][387] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 8, 8), int32] */;
  %314 = qnn.requantize(%313, meta[relay.Constant][388] /* ty=Tensor[(64), float32] */, meta[relay.Constant][389] /* ty=Tensor[(64), int32] */, 7.68602f /* ty=float32 */, 19 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 64, 8, 8), int8] */;
  %315 = qnn.dequantize(%314, 7.68602f /* ty=float32 */, 19 /* ty=int32 */, axis=1) /* ty=Tensor[(1, 64, 8, 8), float32] */;
  %316 = image.resize2d(%315, size=[16, 16], rounding_method="floor", cubic_alpha=-0.75f) /* ty=Tensor[(1, 64, 16, 16), float32] */;
  %317 = qnn.conv2d(%181, meta[relay.Constant][390] /* ty=Tensor[(64, 112, 1, 1), int8] */, 2 /* ty=int32 */, meta[relay.Constant][391] /* ty=Tensor[(64), int32] */, 0.17098f /* ty=float32 */, meta[relay.Constant][392] /* ty=Tensor[(64), float32] */, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 64, 16, 16), int32] */;
  %318 = nn.bias_add(%317, meta[relay.Constant][393] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 16, 16), int32] */;
  %319 = qnn.quantize(%316, 7.68602f /* ty=float32 */, 19 /* ty=int32 */, out_dtype="int8", axis=1) /* ty=Tensor[(1, 64, 16, 16), int8] */;
  %320 = qnn.requantize(%318, meta[relay.Constant][394] /* ty=Tensor[(64), float32] */, meta[relay.Constant][395] /* ty=Tensor[(64), int32] */, 1.35221f /* ty=float32 */, -20 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 64, 16, 16), int8] */;
  %321 = qnn.add(%319, %320, 7.68602f /* ty=float32 */, 19 /* ty=int32 */, 1.35221f /* ty=float32 */, -20 /* ty=int32 */, 6.4583f /* ty=float32 */, 3 /* ty=int32 */) /* ty=Tensor[(1, 64, 16, 16), int8] */;
  %322 = qnn.conv2d(%321, meta[relay.Constant][396] /* ty=Tensor[(64, 1, 3, 3), int8] */, 3 /* ty=int32 */, meta[relay.Constant][397] /* ty=Tensor[(64), int32] */, 6.4583f /* ty=float32 */, meta[relay.Constant][398] /* ty=Tensor[(64), float32] */, padding=[1, 1, 1, 1], groups=64, channels=64, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 64, 16, 16), int32] */;
  %323 = nn.bias_add(%322, meta[relay.Constant][399] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 16, 16), int32] */;
  %324 = qnn.requantize(%323, meta[relay.Constant][400] /* ty=Tensor[(64), float32] */, meta[relay.Constant][401] /* ty=Tensor[(64), int32] */, 24.4204f /* ty=float32 */, 2 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 64, 16, 16), int8] */;
  %325 = qnn.conv2d(%324, meta[relay.Constant][402] /* ty=Tensor[(32, 64, 1, 1), int8] */, 2 /* ty=int32 */, meta[relay.Constant][403] /* ty=Tensor[(32), int32] */, 24.4204f /* ty=float32 */, meta[relay.Constant][404] /* ty=Tensor[(32), float32] */, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 32, 16, 16), int32] */;
  %326 = nn.bias_add(%325, meta[relay.Constant][405] /* ty=Tensor[(32), int32] */) /* ty=Tensor[(1, 32, 16, 16), int32] */;
  %327 = maximum(%326, meta[relay.Constant][406] /* ty=Tensor[(1, 32, 1, 1), int32] */) /* ty=Tensor[(1, 32, 16, 16), int32] */;
  %328 = qnn.requantize(%327, meta[relay.Constant][407] /* ty=Tensor[(32), float32] */, meta[relay.Constant][408] /* ty=Tensor[(32), int32] */, 0.365553f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 32, 16, 16), int8] */;
  %329 = qnn.dequantize(%328, 0.365553f /* ty=float32 */, -128 /* ty=int32 */, axis=1) /* ty=Tensor[(1, 32, 16, 16), float32] */;
  %330 = image.resize2d(%329, size=[32, 32], rounding_method="floor", cubic_alpha=-0.75f) /* ty=Tensor[(1, 32, 32, 32), float32] */;
  %331 = qnn.conv2d(%110, meta[relay.Constant][409] /* ty=Tensor[(32, 56, 1, 1), int8] */, 0 /* ty=int32 */, meta[relay.Constant][410] /* ty=Tensor[(32), int32] */, 0.0647469f /* ty=float32 */, meta[relay.Constant][411] /* ty=Tensor[(32), float32] */, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 32, 32, 32), int32] */;
  %332 = nn.bias_add(%331, meta[relay.Constant][412] /* ty=Tensor[(32), int32] */) /* ty=Tensor[(1, 32, 32, 32), int32] */;
  %333 = qnn.quantize(%330, 0.365553f /* ty=float32 */, -128 /* ty=int32 */, out_dtype="int8", axis=1) /* ty=Tensor[(1, 32, 32, 32), int8] */;
  %334 = qnn.requantize(%332, meta[relay.Constant][413] /* ty=Tensor[(32), float32] */, meta[relay.Constant][414] /* ty=Tensor[(32), int32] */, 0.110455f /* ty=float32 */, 66 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 32, 32, 32), int8] */;
  %335 = qnn.add(%333, %334, 0.365553f /* ty=float32 */, -128 /* ty=int32 */, 0.110455f /* ty=float32 */, 66 /* ty=int32 */, 0.385259f /* ty=float32 */, -73 /* ty=int32 */) /* ty=Tensor[(1, 32, 32, 32), int8] */;
  %336 = qnn.conv2d(%335, meta[relay.Constant][415] /* ty=Tensor[(32, 1, 3, 3), int8] */, -73 /* ty=int32 */, meta[relay.Constant][416] /* ty=Tensor[(32), int32] */, 0.385259f /* ty=float32 */, meta[relay.Constant][417] /* ty=Tensor[(32), float32] */, padding=[1, 1, 1, 1], groups=32, channels=32, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 32, 32, 32), int32] */;
  %337 = nn.bias_add(%336, meta[relay.Constant][418] /* ty=Tensor[(32), int32] */) /* ty=Tensor[(1, 32, 32, 32), int32] */;
  %338 = qnn.requantize(%337, meta[relay.Constant][419] /* ty=Tensor[(32), float32] */, meta[relay.Constant][420] /* ty=Tensor[(32), int32] */, 1.9715f /* ty=float32 */, 14 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 32, 32, 32), int8] */;
  %339 = qnn.conv2d(%338, meta[relay.Constant][421] /* ty=Tensor[(24, 32, 1, 1), int8] */, 14 /* ty=int32 */, meta[relay.Constant][422] /* ty=Tensor[(24), int32] */, 1.9715f /* ty=float32 */, meta[relay.Constant][423] /* ty=Tensor[(24), float32] */, padding=[0, 0, 0, 0], channels=24, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 24, 32, 32), int32] */;
  %340 = nn.bias_add(%339, meta[relay.Constant][424] /* ty=Tensor[(24), int32] */) /* ty=Tensor[(1, 24, 32, 32), int32] */;
  %341 = maximum(%340, meta[relay.Constant][425] /* ty=Tensor[(1, 24, 1, 1), int32] */) /* ty=Tensor[(1, 24, 32, 32), int32] */;
  %342 = qnn.requantize(%341, meta[relay.Constant][426] /* ty=Tensor[(24), float32] */, meta[relay.Constant][427] /* ty=Tensor[(24), int32] */, 0.241872f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 24, 32, 32), int8] */;
  %343 = qnn.dequantize(%342, 0.241872f /* ty=float32 */, -128 /* ty=int32 */, axis=1) /* ty=Tensor[(1, 24, 32, 32), float32] */;
  %344 = image.resize2d(%343, size=[64, 64], rounding_method="floor", cubic_alpha=-0.75f) /* ty=Tensor[(1, 24, 64, 64), float32] */;
  %345 = qnn.conv2d(%57, meta[relay.Constant][428] /* ty=Tensor[(24, 40, 1, 1), int8] */, -16 /* ty=int32 */, meta[relay.Constant][429] /* ty=Tensor[(24), int32] */, 0.0575621f /* ty=float32 */, meta[relay.Constant][430] /* ty=Tensor[(24), float32] */, padding=[0, 0, 0, 0], channels=24, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %346 = nn.bias_add(%345, meta[relay.Constant][431] /* ty=Tensor[(24), int32] */) /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %347 = qnn.quantize(%344, 0.241872f /* ty=float32 */, -128 /* ty=int32 */, out_dtype="int8", axis=1) /* ty=Tensor[(1, 24, 64, 64), int8] */;
  %348 = qnn.requantize(%346, meta[relay.Constant][432] /* ty=Tensor[(24), float32] */, meta[relay.Constant][433] /* ty=Tensor[(24), int32] */, 0.110212f /* ty=float32 */, -4 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 24, 64, 64), int8] */;
  %349 = qnn.add(%347, %348, 0.241872f /* ty=float32 */, -128 /* ty=int32 */, 0.110212f /* ty=float32 */, -4 /* ty=int32 */, 0.245675f /* ty=float32 */, -76 /* ty=int32 */) /* ty=Tensor[(1, 24, 64, 64), int8] */;
  %350 = qnn.conv2d(%349, meta[relay.Constant][434] /* ty=Tensor[(24, 1, 3, 3), int8] */, -76 /* ty=int32 */, meta[relay.Constant][435] /* ty=Tensor[(24), int32] */, 0.245675f /* ty=float32 */, meta[relay.Constant][436] /* ty=Tensor[(24), float32] */, padding=[1, 1, 1, 1], groups=24, channels=24, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %351 = nn.bias_add(%350, meta[relay.Constant][437] /* ty=Tensor[(24), int32] */) /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %352 = qnn.requantize(%351, meta[relay.Constant][438] /* ty=Tensor[(24), float32] */, meta[relay.Constant][439] /* ty=Tensor[(24), int32] */, 3.63486f /* ty=float32 */, -74 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 24, 64, 64), int8] */;
  %353 = qnn.conv2d(%352, meta[relay.Constant][440] /* ty=Tensor[(24, 24, 1, 1), int8] */, -74 /* ty=int32 */, meta[relay.Constant][441] /* ty=Tensor[(24), int32] */, 3.63486f /* ty=float32 */, meta[relay.Constant][442] /* ty=Tensor[(24), float32] */, padding=[0, 0, 0, 0], channels=24, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %354 = nn.bias_add(%353, meta[relay.Constant][443] /* ty=Tensor[(24), int32] */) /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %355 = maximum(%354, meta[relay.Constant][444] /* ty=Tensor[(1, 24, 1, 1), int32] */) /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %356 = qnn.requantize(%355, meta[relay.Constant][445] /* ty=Tensor[(24), float32] */, meta[relay.Constant][446] /* ty=Tensor[(24), int32] */, 0.0200999f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 24, 64, 64), int8] */;
  %357 = qnn.conv2d(%356, meta[relay.Constant][447] /* ty=Tensor[(24, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][448] /* ty=Tensor[(24), int32] */, 0.0200999f /* ty=float32 */, meta[relay.Constant][449] /* ty=Tensor[(24), float32] */, padding=[1, 1, 1, 1], groups=24, channels=24, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %358 = nn.bias_add(%357, meta[relay.Constant][437] /* ty=Tensor[(24), int32] */) /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %359 = qnn.requantize(%358, meta[relay.Constant][450] /* ty=Tensor[(24), float32] */, meta[relay.Constant][451] /* ty=Tensor[(24), int32] */, 0.0293406f /* ty=float32 */, -10 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 24, 64, 64), int8] */;
  %360 = qnn.conv2d(%359, meta[relay.Constant][452] /* ty=Tensor[(96, 24, 1, 1), int8] */, -10 /* ty=int32 */, meta[relay.Constant][453] /* ty=Tensor[(96), int32] */, 0.0293406f /* ty=float32 */, meta[relay.Constant][454] /* ty=Tensor[(96), float32] */, padding=[0, 0, 0, 0], channels=96, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 96, 64, 64), int32] */;
  %361 = nn.bias_add(%360, meta[relay.Constant][455] /* ty=Tensor[(96), int32] */) /* ty=Tensor[(1, 96, 64, 64), int32] */;
  %362 = maximum(%361, meta[relay.Constant][456] /* ty=Tensor[(1, 96, 1, 1), int32] */) /* ty=Tensor[(1, 96, 64, 64), int32] */;
  %363 = qnn.requantize(%362, meta[relay.Constant][457] /* ty=Tensor[(96), float32] */, meta[relay.Constant][458] /* ty=Tensor[(96), int32] */, 0.0522609f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 96, 64, 64), int8] */;
  %364 = qnn.conv2d(%363, meta[relay.Constant][459] /* ty=Tensor[(17, 96, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][460] /* ty=Tensor[(17), int32] */, 0.0522609f /* ty=float32 */, meta[relay.Constant][461] /* ty=Tensor[(17), float32] */, padding=[0, 0, 0, 0], channels=17, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 17, 64, 64), int32] */;
  %365 = nn.bias_add(%364, meta[relay.Constant][462] /* ty=Tensor[(17), int32] */) /* ty=Tensor[(1, 17, 64, 64), int32] */;
  %366 = qnn.requantize(%365, meta[relay.Constant][463] /* ty=Tensor[(17), float32] */, meta[relay.Constant][464] /* ty=Tensor[(17), int32] */, 0.50485f /* ty=float32 */, 119 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 17, 64, 64), int8] */;
  %367 = qnn.dequantize(%366, 0.50485f /* ty=float32 */, 119 /* ty=int32 */, axis=1) /* ty=Tensor[(1, 17, 64, 64), float32] */;
  %368 = sigmoid(%367) /* ty=Tensor[(1, 17, 64, 64), float32] */;
  %369 = qnn.quantize(%368, 0.00390625f /* ty=float32 */, -128 /* ty=int32 */, out_dtype="int8", axis=1) /* ty=Tensor[(1, 17, 64, 64), int8] */;
  %370 = transpose(%369, axes=[0, 2, 3, 1]) /* ty=Tensor[(1, 64, 64, 17), int8] */;
  %371 = qnn.conv2d(%356, meta[relay.Constant][466] /* ty=Tensor[(24, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][467] /* ty=Tensor[(24), int32] */, 0.0200999f /* ty=float32 */, meta[relay.Constant][468] /* ty=Tensor[(24), float32] */, padding=[1, 1, 1, 1], groups=24, channels=24, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %372 = nn.bias_add(%371, meta[relay.Constant][437] /* ty=Tensor[(24), int32] */) /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %373 = qnn.requantize(%372, meta[relay.Constant][469] /* ty=Tensor[(24), float32] */, meta[relay.Constant][470] /* ty=Tensor[(24), int32] */, 0.0665726f /* ty=float32 */, 46 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 24, 64, 64), int8] */;
  %374 = qnn.conv2d(%373, meta[relay.Constant][471] /* ty=Tensor[(96, 24, 1, 1), int8] */, 46 /* ty=int32 */, meta[relay.Constant][472] /* ty=Tensor[(96), int32] */, 0.0665726f /* ty=float32 */, meta[relay.Constant][473] /* ty=Tensor[(96), float32] */, padding=[0, 0, 0, 0], channels=96, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 96, 64, 64), int32] */;
  %375 = nn.bias_add(%374, meta[relay.Constant][474] /* ty=Tensor[(96), int32] */) /* ty=Tensor[(1, 96, 64, 64), int32] */;
  %376 = maximum(%375, meta[relay.Constant][475] /* ty=Tensor[(1, 96, 1, 1), int32] */) /* ty=Tensor[(1, 96, 64, 64), int32] */;
  %377 = qnn.requantize(%376, meta[relay.Constant][476] /* ty=Tensor[(96), float32] */, meta[relay.Constant][477] /* ty=Tensor[(96), int32] */, 0.121168f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 96, 64, 64), int8] */;
  %378 = qnn.conv2d(%377, meta[relay.Constant][478] /* ty=Tensor[(1, 96, 1, 1), int8] */, -128 /* ty=int32 */, 0 /* ty=int32 */, 0.121168f /* ty=float32 */, 0.00849772f /* ty=float32 */, padding=[0, 0, 0, 0], channels=1, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 1, 64, 64), int32] */;
  %379 = nn.bias_add(%378, meta[relay.Constant][479] /* ty=Tensor[(1), int32] */) /* ty=Tensor[(1, 1, 64, 64), int32] */;
  %380 = qnn.requantize(%379, 0.00102965f /* ty=float32 */, 0 /* ty=int32 */, 0.249596f /* ty=float32 */, 110 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 1, 64, 64), int8] */;
  %381 = qnn.dequantize(%380, 0.249596f /* ty=float32 */, 110 /* ty=int32 */, axis=1) /* ty=Tensor[(1, 1, 64, 64), float32] */;
  %382 = sigmoid(%381) /* ty=Tensor[(1, 1, 64, 64), float32] */;
  %383 = qnn.quantize(%382, 0.00390625f /* ty=float32 */, -128 /* ty=int32 */, out_dtype="int8", axis=1) /* ty=Tensor[(1, 1, 64, 64), int8] */;
  %384 = reshape(%383, newshape=[1, 64, 64, 1]) /* ty=Tensor[(1, 64, 64, 1), int8] */;
  %385 = qnn.mul(%384, meta[relay.Constant][480] /* ty=Tensor[(64, 64, 1), int8] */, 0.00390625f /* ty=float32 */, -128 /* ty=int32 */, 0.00217865f /* ty=float32 */, -128 /* ty=int32 */, 0.00210513f /* ty=float32 */, -128 /* ty=int32 */) /* ty=Tensor[(1, 64, 64, 1), int8] */;
  %386 = reshape(%385, newshape=[1, -1, 1]) /* ty=Tensor[(1, 4096, 1), int8] */;
  %387 = qnn.dequantize(%386, 0.00210513f /* ty=float32 */, -128 /* ty=int32 */, axis=1) /* ty=Tensor[(1, 4096, 1), float32] */;
  %388 = argmax(%387, axis=[1]) /* ty=Tensor[(1, 1), int32] */;
  %389 = cast(%388, dtype="int64") /* ty=Tensor[(1, 1), int64] */;
  %390 = cast(%389, dtype="int32") /* ty=Tensor[(1, 1), int32] */;
  %391 = divide(%390, 64 /* ty=int32 */) /* ty=Tensor[(1, 1), int32] */;
  %392 = cast(%391, dtype="float32") /* ty=Tensor[(1, 1), float32] */;
  %393 = qnn.conv2d(%356, meta[relay.Constant][481] /* ty=Tensor[(24, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][482] /* ty=Tensor[(24), int32] */, 0.0200999f /* ty=float32 */, meta[relay.Constant][483] /* ty=Tensor[(24), float32] */, padding=[1, 1, 1, 1], groups=24, channels=24, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %394 = nn.bias_add(%393, meta[relay.Constant][437] /* ty=Tensor[(24), int32] */) /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %395 = qnn.requantize(%394, meta[relay.Constant][484] /* ty=Tensor[(24), float32] */, meta[relay.Constant][485] /* ty=Tensor[(24), int32] */, 0.0394016f /* ty=float32 */, 18 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 24, 64, 64), int8] */;
  %396 = qnn.conv2d(%395, meta[relay.Constant][486] /* ty=Tensor[(96, 24, 1, 1), int8] */, 18 /* ty=int32 */, meta[relay.Constant][487] /* ty=Tensor[(96), int32] */, 0.0394016f /* ty=float32 */, meta[relay.Constant][488] /* ty=Tensor[(96), float32] */, padding=[0, 0, 0, 0], channels=96, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 96, 64, 64), int32] */;
  %397 = nn.bias_add(%396, meta[relay.Constant][489] /* ty=Tensor[(96), int32] */) /* ty=Tensor[(1, 96, 64, 64), int32] */;
  %398 = maximum(%397, meta[relay.Constant][490] /* ty=Tensor[(1, 96, 1, 1), int32] */) /* ty=Tensor[(1, 96, 64, 64), int32] */;
  %399 = qnn.requantize(%398, meta[relay.Constant][491] /* ty=Tensor[(96), float32] */, meta[relay.Constant][492] /* ty=Tensor[(96), int32] */, 0.0782168f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 96, 64, 64), int8] */;
  %400 = qnn.conv2d(%399, meta[relay.Constant][493] /* ty=Tensor[(34, 96, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][494] /* ty=Tensor[(34), int32] */, 0.0782168f /* ty=float32 */, meta[relay.Constant][495] /* ty=Tensor[(34), float32] */, padding=[0, 0, 0, 0], channels=34, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 34, 64, 64), int32] */;
  %401 = nn.bias_add(%400, meta[relay.Constant][496] /* ty=Tensor[(34), int32] */) /* ty=Tensor[(1, 34, 64, 64), int32] */;
  %402 = qnn.requantize(%401, meta[relay.Constant][497] /* ty=Tensor[(34), float32] */, meta[relay.Constant][498] /* ty=Tensor[(34), int32] */, 0.710464f /* ty=float32 */, 11 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 34, 64, 64), int8] */;
  %403 = reshape(%391, newshape=[-1]) /* ty=Tensor[(1), int32] */;
  %404 = multiply(%391, 64 /* ty=int32 */) /* ty=Tensor[(1, 1), int32] */;
  %405 = subtract(%390, %404) /* ty=Tensor[(1, 1), int32] */;
  %406 = reshape(%405, newshape=[-1]) /* ty=Tensor[(1), int32] */;
  %407 = expand_dims(%403, axis=1) /* ty=Tensor[(1, 1), int32] */;
  %408 = expand_dims(%406, axis=1) /* ty=Tensor[(1, 1), int32] */;
  %409 = (meta[relay.Constant][499] /* ty=Tensor[(1, 1), int32] */, %407, %408);
  %410 = concatenate(%409, axis=1) /* ty=Tensor[(1, 3), int32] */;
  %411 = cast(%410, dtype="int64") /* ty=Tensor[(1, 3), int64] */;
  %412 = transpose(%402, axes=[0, 2, 3, 1]) /* ty=Tensor[(1, 64, 64, 34), int8] */;
  %413 = transpose(%411, axes=[-1, 0]) /* ty=Tensor[(3, 1), int64] */;
  %414 = gather_nd(%412, %413, index_rank=3) /* ty=Tensor[(1, 34), int8] */;
  %415 = reshape(%414, newshape=[17, -1]) /* ty=Tensor[(17, 2), int8] */;
  %416 = split(%415, indices_or_sections=2, axis=1) /* ty=(Tensor[(17, 1), int8], Tensor[(17, 1), int8]) */;
  %417 = %416.0;
  %418 = qnn.quantize(%392, 0.137255f /* ty=float32 */, -128 /* ty=int32 */, out_dtype="int8", axis=1) /* ty=Tensor[(1, 1), int8] */;
  %419 = squeeze(%417, axis=[1]) /* ty=Tensor[(17), int8] */;
  %420 = qnn.add(%418, %419, 0.137255f /* ty=float32 */, -128 /* ty=int32 */, 0.710464f /* ty=float32 */, 11 /* ty=int32 */, 0.266113f /* ty=float32 */, -128 /* ty=int32 */) /* ty=Tensor[(1, 17), int8] */;
  %421 = qnn.subtract(meta[relay.Constant][465] /* ty=Tensor[(64, 64, 1), int8] */, %420, 0.247059f /* ty=float32 */, -128 /* ty=int32 */, 0.266113f /* ty=float32 */, -128 /* ty=int32 */, 0.500793f /* ty=float32 */, 8 /* ty=int32 */) /* ty=Tensor[(64, 64, 17), int8] */;
  %422 = cast(%405, dtype="float32") /* ty=Tensor[(1, 1), float32] */;
  %423 = %416.1;
  %424 = qnn.quantize(%422, 0.145098f /* ty=float32 */, -128 /* ty=int32 */, out_dtype="int8", axis=1) /* ty=Tensor[(1, 1), int8] */;
  %425 = squeeze(%423, axis=[1]) /* ty=Tensor[(17), int8] */;
  %426 = qnn.add(%424, %425, 0.145098f /* ty=float32 */, -128 /* ty=int32 */, 0.710464f /* ty=float32 */, 11 /* ty=int32 */, 0.236722f /* ty=float32 */, -128 /* ty=int32 */) /* ty=Tensor[(1, 17), int8] */;
  %427 = qnn.subtract(meta[relay.Constant][500] /* ty=Tensor[(64, 64, 1), int8] */, %426, 0.247059f /* ty=float32 */, -128 /* ty=int32 */, 0.236722f /* ty=float32 */, -128 /* ty=int32 */, 0.478789f /* ty=float32 */, -2 /* ty=int32 */) /* ty=Tensor[(64, 64, 17), int8] */;
  %428 = qnn.mul(%421, %421, 0.500793f /* ty=float32 */, 8 /* ty=int32 */, 0.500793f /* ty=float32 */, 8 /* ty=int32 */, 18.0581f /* ty=float32 */, -128 /* ty=int32 */) /* ty=Tensor[(64, 64, 17), int8] */;
  %429 = qnn.mul(%427, %427, 0.478789f /* ty=float32 */, -2 /* ty=int32 */, 0.478789f /* ty=float32 */, -2 /* ty=int32 */, 14.9421f /* ty=float32 */, -128 /* ty=int32 */) /* ty=Tensor[(64, 64, 17), int8] */;
  %430 = qnn.add(%428, %429, 18.0581f /* ty=float32 */, -128 /* ty=int32 */, 14.9421f /* ty=float32 */, -128 /* ty=int32 */, 27.8113f /* ty=float32 */, -128 /* ty=int32 */) /* ty=Tensor[(64, 64, 17), int8] */;
  %431 = qnn.dequantize(%430, 27.8113f /* ty=float32 */, -128 /* ty=int32 */, axis=1) /* ty=Tensor[(64, 64, 17), float32] */;
  %432 = sqrt(%431) /* ty=Tensor[(64, 64, 17), float32] */;
  %433 = qnn.quantize(%432, 0.330248f /* ty=float32 */, -128 /* ty=int32 */, out_dtype="int8", axis=1) /* ty=Tensor[(64, 64, 17), int8] */;
  %434 = qnn.add(%433, meta[relay.Constant][1] /* ty=int8 */, 0.330248f /* ty=float32 */, -128 /* ty=int32 */, 0.00705882f /* ty=float32 */, -128 /* ty=int32 */, 0.337307f /* ty=float32 */, -128 /* ty=int32 */) /* ty=Tensor[(64, 64, 17), int8] */;
  %435 = qnn.dequantize(%370, 0.00390625f /* ty=float32 */, -128 /* ty=int32 */, axis=1) /* ty=Tensor[(1, 64, 64, 17), float32] */;
  %436 = qnn.dequantize(%434, 0.337307f /* ty=float32 */, -128 /* ty=int32 */, axis=1) /* ty=Tensor[(64, 64, 17), float32] */;
  %437 = divide(%435, %436) /* ty=Tensor[(1, 64, 64, 17), float32] */;
  %438 = qnn.quantize(%437, 0.00205939f /* ty=float32 */, -128 /* ty=int32 */, out_dtype="int8", axis=1) /* ty=Tensor[(1, 64, 64, 17), int8] */;
  %439 = reshape(%438, newshape=[1, -1, 17]) /* ty=Tensor[(1, 4096, 17), int8] */;
  %440 = qnn.dequantize(%439, 0.00205939f /* ty=float32 */, -128 /* ty=int32 */, axis=1) /* ty=Tensor[(1, 4096, 17), float32] */;
  %441 = argmax(%440, axis=[1]) /* ty=Tensor[(1, 17), int32] */;
  %442 = cast(%441, dtype="int64") /* ty=Tensor[(1, 17), int64] */;
  %443 = cast(%442, dtype="int32") /* ty=Tensor[(1, 17), int32] */;
  %444 = divide(%443, 64 /* ty=int32 */) /* ty=Tensor[(1, 17), int32] */;
  %445 = cast(%444, dtype="float32") /* ty=Tensor[(1, 17), float32] */;
  %446 = qnn.conv2d(%356, meta[relay.Constant][501] /* ty=Tensor[(24, 1, 3, 3), int8] */, -128 /* ty=int32 */, meta[relay.Constant][502] /* ty=Tensor[(24), int32] */, 0.0200999f /* ty=float32 */, meta[relay.Constant][503] /* ty=Tensor[(24), float32] */, padding=[1, 1, 1, 1], groups=24, channels=24, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %447 = nn.bias_add(%446, meta[relay.Constant][437] /* ty=Tensor[(24), int32] */) /* ty=Tensor[(1, 24, 64, 64), int32] */;
  %448 = qnn.requantize(%447, meta[relay.Constant][504] /* ty=Tensor[(24), float32] */, meta[relay.Constant][505] /* ty=Tensor[(24), int32] */, 0.0237176f /* ty=float32 */, 3 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 24, 64, 64), int8] */;
  %449 = qnn.conv2d(%448, meta[relay.Constant][506] /* ty=Tensor[(96, 24, 1, 1), int8] */, 3 /* ty=int32 */, meta[relay.Constant][507] /* ty=Tensor[(96), int32] */, 0.0237176f /* ty=float32 */, meta[relay.Constant][508] /* ty=Tensor[(96), float32] */, padding=[0, 0, 0, 0], channels=96, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 96, 64, 64), int32] */;
  %450 = nn.bias_add(%449, meta[relay.Constant][509] /* ty=Tensor[(96), int32] */) /* ty=Tensor[(1, 96, 64, 64), int32] */;
  %451 = maximum(%450, meta[relay.Constant][510] /* ty=Tensor[(1, 96, 1, 1), int32] */) /* ty=Tensor[(1, 96, 64, 64), int32] */;
  %452 = qnn.requantize(%451, meta[relay.Constant][511] /* ty=Tensor[(96), float32] */, meta[relay.Constant][512] /* ty=Tensor[(96), int32] */, 0.0541646f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 96, 64, 64), int8] */;
  %453 = qnn.conv2d(%452, meta[relay.Constant][513] /* ty=Tensor[(34, 96, 1, 1), int8] */, -128 /* ty=int32 */, meta[relay.Constant][514] /* ty=Tensor[(34), int32] */, 0.0541646f /* ty=float32 */, meta[relay.Constant][515] /* ty=Tensor[(34), float32] */, padding=[0, 0, 0, 0], channels=34, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(1, 34, 64, 64), int32] */;
  %454 = nn.bias_add(%453, meta[relay.Constant][516] /* ty=Tensor[(34), int32] */) /* ty=Tensor[(1, 34, 64, 64), int32] */;
  %455 = qnn.requantize(%454, meta[relay.Constant][517] /* ty=Tensor[(34), float32] */, meta[relay.Constant][518] /* ty=Tensor[(34), int32] */, 0.231599f /* ty=float32 */, -9 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 34, 64, 64), int8] */;
  %456 = reshape(%444, newshape=[-1]) /* ty=Tensor[(17), int32] */;
  %457 = multiply(%444, 64 /* ty=int32 */) /* ty=Tensor[(1, 17), int32] */;
  %458 = subtract(%443, %457) /* ty=Tensor[(1, 17), int32] */;
  %459 = reshape(%458, newshape=[-1]) /* ty=Tensor[(17), int32] */;
  %460 = expand_dims(%456, axis=1) /* ty=Tensor[(17, 1), int32] */;
  %461 = expand_dims(%459, axis=1) /* ty=Tensor[(17, 1), int32] */;
  %462 = (meta[relay.Constant][519] /* ty=Tensor[(17, 1), int32] */, %460, %461);
  %463 = concatenate(%462, axis=1) /* ty=Tensor[(17, 3), int32] */;
  %464 = cast(%463, dtype="int64") /* ty=Tensor[(17, 3), int64] */;
  %465 = transpose(%455, axes=[0, 2, 3, 1]) /* ty=Tensor[(1, 64, 64, 34), int8] */;
  %466 = transpose(%464, axes=[-1, 0]) /* ty=Tensor[(3, 17), int64] */;
  %467 = gather_nd(%465, %466, index_rank=3) /* ty=Tensor[(17, 34), int8] */;
  %468 = reshape(%467, newshape=[17, 17, -1]) /* ty=Tensor[(17, 17, 2), int8] */;
  %469 = gather_nd(%468, meta[relay.Constant][520] /* ty=Tensor[(2, 17), int64] */, index_rank=2) /* ty=Tensor[(17, 2), int8] */;
  %470 = split(%469, indices_or_sections=2, axis=1) /* ty=(Tensor[(17, 1), int8], Tensor[(17, 1), int8]) */;
  %471 = %470.0;
  %472 = squeeze(%471, axis=[1]) /* ty=Tensor[(17), int8] */;
  %473 = qnn.quantize(%445, 0.247059f /* ty=float32 */, -128 /* ty=int32 */, out_dtype="int8", axis=1) /* ty=Tensor[(1, 17), int8] */;
  %474 = reshape(%472, newshape=[1, 17]) /* ty=Tensor[(1, 17), int8] */;
  %475 = qnn.add(%473, %474, 0.247059f /* ty=float32 */, -128 /* ty=int32 */, 0.231599f /* ty=float32 */, -9 /* ty=int32 */, 0.256906f /* ty=float32 */, -128 /* ty=int32 */) /* ty=Tensor[(1, 17), int8] */;
  %476 = cast(%458, dtype="float32") /* ty=Tensor[(1, 17), float32] */;
  %477 = %470.1;
  %478 = squeeze(%477, axis=[1]) /* ty=Tensor[(17), int8] */;
  %479 = qnn.quantize(%476, 0.247059f /* ty=float32 */, -128 /* ty=int32 */, out_dtype="int8", axis=1) /* ty=Tensor[(1, 17), int8] */;
  %480 = reshape(%478, newshape=[1, 17]) /* ty=Tensor[(1, 17), int8] */;
  %481 = qnn.add(%479, %480, 0.247059f /* ty=float32 */, -128 /* ty=int32 */, 0.231599f /* ty=float32 */, -9 /* ty=int32 */, 0.256906f /* ty=float32 */, -128 /* ty=int32 */) /* ty=Tensor[(1, 17), int8] */;
  %482 = expand_dims(%475, axis=2) /* ty=Tensor[(1, 17, 1), int8] */;
  %483 = expand_dims(%481, axis=2) /* ty=Tensor[(1, 17, 1), int8] */;
  %484 = (%482, %483);
  %485 = concatenate(%484, axis=2) /* ty=Tensor[(1, 17, 2), int8] */;
  %486 = reshape(%485, newshape=[1, 1, 17, 2]) /* ty=Tensor[(1, 1, 17, 2), int8] */;
  %487 = qnn.requantize(%369, 0.00390625f /* ty=float32 */, -128 /* ty=int32 */, 0.00401416f /* ty=float32 */, -128 /* ty=int32 */, axis=1, out_dtype="int8") /* ty=Tensor[(1, 17, 64, 64), int8] */;
  %488 = (%463, meta[relay.Constant][522] /* ty=Tensor[(17, 1), int32] */);
  %489 = concatenate(%488, axis=1) /* ty=Tensor[(17, 4), int32] */;
  %490 = cast(%489, dtype="int64") /* ty=Tensor[(17, 4), int64] */;
  %491 = transpose(%487, axes=[0, 2, 3, 1]) /* ty=Tensor[(1, 64, 64, 17), int8] */;
  %492 = transpose(%490, axes=[-1, 0]) /* ty=Tensor[(4, 17), int64] */;
  %493 = gather_nd(%491, %492, index_rank=4) /* ty=Tensor[(17), int8] */;
  %494 = qnn.mul(%486, meta[relay.Constant][521] /* ty=Tensor[(1, 1, 1, 2), int8] */, 0.256906f /* ty=float32 */, -128 /* ty=int32 */, 6.12745e-05f /* ty=float32 */, -128 /* ty=int32 */, 0.00401416f /* ty=float32 */, -128 /* ty=int32 */) /* ty=Tensor[(1, 1, 17, 2), int8] */;
  %495 = reshape(%493, newshape=[1, 1, 17, 1]) /* ty=Tensor[(1, 1, 17, 1), int8] */;
  %496 = (%494, %495);
  %497 = concatenate(%496, axis=3) /* ty=Tensor[(1, 1, 17, 3), int8] */;
  qnn.dequantize(%497, 0.00401416f /* ty=float32 */, -128 /* ty=int32 */, axis=1) /* ty=Tensor[(1, 1, 17, 3), float32] */
}
